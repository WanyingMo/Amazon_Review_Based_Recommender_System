{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.deeprec_utils import (\n",
    "    prepare_hparams\n",
    ")\n",
    "from recommenders.datasets.amazon_reviews import download_and_extract, data_preprocessing\n",
    "\n",
    "from recommenders.models.deeprec.io.sequential_iterator import SequentialIterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 400\n",
    "RANDOM_SEED = 25\n",
    "data_path = \"../../Data/Amazon_Movie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(data_path, r'train_data')\n",
    "valid_file = os.path.join(data_path, r'valid_data')\n",
    "test_file = os.path.join(data_path, r'test_data')\n",
    "user_vocab = os.path.join(data_path, r'user_vocab.pkl')\n",
    "item_vocab = os.path.join(data_path, r'item_vocab.pkl')\n",
    "cate_vocab = os.path.join(data_path, r'category_vocab.pkl')\n",
    "output_file = os.path.join(data_path, r'output.txt')\n",
    "\n",
    "reviews_name = 'reviews_Movies_and_TV_5.json'\n",
    "meta_name = 'meta_Movies_and_TV.json'\n",
    "reviews_file = os.path.join(data_path, reviews_name)\n",
    "meta_file = os.path.join(data_path, meta_name)\n",
    "train_num_ngs = 4 # number of negative instances with a positive instance for training\n",
    "valid_num_ngs = 4 # number of negative instances with a positive instance for validation\n",
    "test_num_ngs = 9 # number of negative instances with a positive instance for testing\n",
    "sample_rate = 0.01 # sample a small item set for training and testing here for fast example\n",
    "\n",
    "input_files = [reviews_file, meta_file, train_file, valid_file, test_file, user_vocab, item_vocab, cate_vocab]\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    download_and_extract(reviews_name, reviews_file)\n",
    "    download_and_extract(meta_name, meta_file)\n",
    "    data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_creator = SequentialIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sli-Rec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z. Yu, J. Lian, A. Mahmoody, G. Liu and X. Xie, \"Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation\", in Proceedings of the 28th International Joint Conferences on Artificial Intelligence, IJCAIâ€™19, Pages 4213-4219, AAAI Press, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = './sli_rec.yaml'\n",
    "hparams = prepare_hparams(\n",
    "    yaml_file,\n",
    "    embed_l2=0.,\n",
    "    layer_l2=0., \n",
    "    learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_step=20,\n",
    "    user_vocab=user_vocab,\n",
    "    item_vocab=item_vocab,\n",
    "    cate_vocab=cate_vocab,\n",
    "    need_sample=True,\n",
    "    train_num_ngs=train_num_ngs # provides the number of negative instances for each positive instance for loss computation.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from recommenders.models.deeprec.models.sequential.sli_rec import SLI_RECModel as SeqModel\n",
    "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5011,\n",
       " 'logloss': 0.6931,\n",
       " 'mean_mrr': 0.2782,\n",
       " 'ndcg@2': 0.1463,\n",
       " 'ndcg@6': 0.3114,\n",
       " 'ndcg@10': 0.4426,\n",
       " 'group_auc': 0.5015}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sli_rec_test_result_before_training = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "sli_rec_test_result_before_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20 , total_loss: 1.6096, data_loss: 1.6096\n",
      "step 40 , total_loss: 1.6047, data_loss: 1.6047\n",
      "eval valid at epoch 1: auc:0.5135,logloss:0.6931,mean_mrr:0.4685,ndcg@2:0.3427,ndcg@6:0.5988,ndcg@10:0.5988,group_auc:0.5169\n",
      "step 20 , total_loss: 1.5626, data_loss: 1.5626\n",
      "step 40 , total_loss: 1.4966, data_loss: 1.4966\n",
      "eval valid at epoch 2: auc:0.5995,logloss:0.6919,mean_mrr:0.5109,ndcg@2:0.4063,ndcg@6:0.6315,ndcg@10:0.6315,group_auc:0.5717\n",
      "step 20 , total_loss: 1.4076, data_loss: 1.4076\n",
      "step 40 , total_loss: 1.3575, data_loss: 1.3575\n",
      "eval valid at epoch 3: auc:0.6735,logloss:0.7333,mean_mrr:0.5918,ndcg@2:0.5194,ndcg@6:0.6934,ndcg@10:0.6934,group_auc:0.6705\n",
      "step 20 , total_loss: 1.3021, data_loss: 1.3021\n",
      "step 40 , total_loss: 1.2554, data_loss: 1.2554\n",
      "eval valid at epoch 4: auc:0.7189,logloss:0.6249,mean_mrr:0.6354,ndcg@2:0.5745,ndcg@6:0.7263,ndcg@10:0.7263,group_auc:0.7089\n",
      "step 20 , total_loss: 1.2412, data_loss: 1.2412\n",
      "step 40 , total_loss: 1.2948, data_loss: 1.2948\n",
      "eval valid at epoch 5: auc:0.7254,logloss:0.5877,mean_mrr:0.6471,ndcg@2:0.5886,ndcg@6:0.7351,ndcg@10:0.7351,group_auc:0.7184\n",
      "step 20 , total_loss: 1.2257, data_loss: 1.2257\n",
      "step 40 , total_loss: 1.2331, data_loss: 1.2331\n",
      "eval valid at epoch 6: auc:0.7353,logloss:0.5638,mean_mrr:0.6519,ndcg@2:0.5956,ndcg@6:0.7388,ndcg@10:0.7388,group_auc:0.7234\n",
      "step 20 , total_loss: 1.2167, data_loss: 1.2167\n",
      "step 40 , total_loss: 1.2467, data_loss: 1.2467\n",
      "eval valid at epoch 7: auc:0.7332,logloss:0.5335,mean_mrr:0.6534,ndcg@2:0.5973,ndcg@6:0.7399,ndcg@10:0.7399,group_auc:0.7246\n",
      "step 20 , total_loss: 1.1849, data_loss: 1.1849\n",
      "step 40 , total_loss: 1.1754, data_loss: 1.1754\n",
      "eval valid at epoch 8: auc:0.7409,logloss:0.5405,mean_mrr:0.6644,ndcg@2:0.6098,ndcg@6:0.7481,ndcg@10:0.7481,group_auc:0.7334\n",
      "step 20 , total_loss: 1.1893, data_loss: 1.1893\n",
      "step 40 , total_loss: 1.1622, data_loss: 1.1622\n",
      "eval valid at epoch 9: auc:0.7399,logloss:0.5596,mean_mrr:0.665,ndcg@2:0.6104,ndcg@6:0.7486,ndcg@10:0.7486,group_auc:0.7329\n",
      "step 20 , total_loss: 1.2020, data_loss: 1.2020\n",
      "step 40 , total_loss: 1.1635, data_loss: 1.1635\n",
      "eval valid at epoch 10: auc:0.7452,logloss:0.5678,mean_mrr:0.6714,ndcg@2:0.6175,ndcg@6:0.7534,ndcg@10:0.7534,group_auc:0.7383\n",
      "[(1, {'auc': 0.5135, 'logloss': 0.6931, 'mean_mrr': 0.4685, 'ndcg@2': 0.3427, 'ndcg@6': 0.5988, 'ndcg@10': 0.5988, 'group_auc': 0.5169}), (2, {'auc': 0.5995, 'logloss': 0.6919, 'mean_mrr': 0.5109, 'ndcg@2': 0.4063, 'ndcg@6': 0.6315, 'ndcg@10': 0.6315, 'group_auc': 0.5717}), (3, {'auc': 0.6735, 'logloss': 0.7333, 'mean_mrr': 0.5918, 'ndcg@2': 0.5194, 'ndcg@6': 0.6934, 'ndcg@10': 0.6934, 'group_auc': 0.6705}), (4, {'auc': 0.7189, 'logloss': 0.6249, 'mean_mrr': 0.6354, 'ndcg@2': 0.5745, 'ndcg@6': 0.7263, 'ndcg@10': 0.7263, 'group_auc': 0.7089}), (5, {'auc': 0.7254, 'logloss': 0.5877, 'mean_mrr': 0.6471, 'ndcg@2': 0.5886, 'ndcg@6': 0.7351, 'ndcg@10': 0.7351, 'group_auc': 0.7184}), (6, {'auc': 0.7353, 'logloss': 0.5638, 'mean_mrr': 0.6519, 'ndcg@2': 0.5956, 'ndcg@6': 0.7388, 'ndcg@10': 0.7388, 'group_auc': 0.7234}), (7, {'auc': 0.7332, 'logloss': 0.5335, 'mean_mrr': 0.6534, 'ndcg@2': 0.5973, 'ndcg@6': 0.7399, 'ndcg@10': 0.7399, 'group_auc': 0.7246}), (8, {'auc': 0.7409, 'logloss': 0.5405, 'mean_mrr': 0.6644, 'ndcg@2': 0.6098, 'ndcg@6': 0.7481, 'ndcg@10': 0.7481, 'group_auc': 0.7334}), (9, {'auc': 0.7399, 'logloss': 0.5596, 'mean_mrr': 0.665, 'ndcg@2': 0.6104, 'ndcg@6': 0.7486, 'ndcg@10': 0.7486, 'group_auc': 0.7329}), (10, {'auc': 0.7452, 'logloss': 0.5678, 'mean_mrr': 0.6714, 'ndcg@2': 0.6175, 'ndcg@6': 0.7534, 'ndcg@10': 0.7534, 'group_auc': 0.7383})]\n",
      "best epoch: 10\n",
      "Time cost for training is 7.35 mins\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    if os.path.exists(\"./model/slirec/\"):\n",
    "        model_path = os.path.join(\"./model/slirec/\", \"best_model\")\n",
    "        model.load_model(model_path)\n",
    "    else:\n",
    "        model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs, eval_metric=)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# sli_rec_training_result = []\n",
    "# for i in range(EPOCHS):\n",
    "#     epoch_model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
    "#     model_path = os.path.join(\"./model/slirec/\", \"epoch_\" + str(i + 1))\n",
    "#     epoch_model.load_model(model_path)\n",
    "#     print('loading saved model in {0}'.format(model_path))\n",
    "#     sli_rec_training_result.append((i + 1, epoch_model.run_eval(valid_file, num_ngs=valid_num_ngs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7177,\n",
       " 'logloss': 0.5588,\n",
       " 'mean_mrr': 0.4862,\n",
       " 'ndcg@2': 0.3986,\n",
       " 'ndcg@6': 0.5526,\n",
       " 'ndcg@10': 0.6077,\n",
       " 'group_auc': 0.7066}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sli_rec_test_result_after_training = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "sli_rec_test_result_after_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2SVD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z. Yu, J. Lian, A. Mahmoody, G. Liu and X. Xie, \"Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation\", in Proceedings of the 28th International Joint Conferences on Artificial Intelligence, IJCAIâ€™19, Pages 4213-4219, AAAI Press, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = './asvd.yaml'\n",
    "hparams = prepare_hparams(\n",
    "    yaml_file,\n",
    "    embed_l2=0.,\n",
    "    layer_l2=0., \n",
    "    learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_step=20,\n",
    "    user_vocab=user_vocab,\n",
    "    item_vocab=item_vocab,\n",
    "    cate_vocab=cate_vocab,\n",
    "    need_sample=True,\n",
    "    train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel\n",
    "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5027,\n",
       " 'logloss': 0.6931,\n",
       " 'mean_mrr': 0.2783,\n",
       " 'ndcg@2': 0.1467,\n",
       " 'ndcg@6': 0.3107,\n",
       " 'ndcg@10': 0.4426,\n",
       " 'group_auc': 0.5018}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2svd_test_result_before_training = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "a2svd_test_result_before_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20 , total_loss: 1.6081, data_loss: 1.6081\n",
      "step 40 , total_loss: 1.6038, data_loss: 1.6038\n",
      "eval valid at epoch 1: auc:0.4953,logloss:0.6931,mean_mrr:0.4511,ndcg@2:0.3177,ndcg@6:0.5855,ndcg@10:0.5855,group_auc:0.4945\n",
      "step 20 , total_loss: 1.5984, data_loss: 1.5984\n",
      "step 40 , total_loss: 1.5614, data_loss: 1.5614\n",
      "eval valid at epoch 2: auc:0.5057,logloss:0.6889,mean_mrr:0.4558,ndcg@2:0.3259,ndcg@6:0.5889,ndcg@10:0.5889,group_auc:0.4959\n",
      "step 20 , total_loss: 1.5203, data_loss: 1.5203\n",
      "step 40 , total_loss: 1.4824, data_loss: 1.4824\n",
      "eval valid at epoch 3: auc:0.6579,logloss:0.6493,mean_mrr:0.57,ndcg@2:0.4862,ndcg@6:0.6768,ndcg@10:0.6768,group_auc:0.6438\n",
      "step 20 , total_loss: 1.3980, data_loss: 1.3980\n",
      "step 40 , total_loss: 1.3700, data_loss: 1.3700\n",
      "eval valid at epoch 4: auc:0.6847,logloss:0.5602,mean_mrr:0.603,ndcg@2:0.5344,ndcg@6:0.702,ndcg@10:0.702,group_auc:0.6812\n",
      "step 20 , total_loss: 1.3265, data_loss: 1.3265\n",
      "step 40 , total_loss: 1.3484, data_loss: 1.3484\n",
      "eval valid at epoch 5: auc:0.6954,logloss:0.5262,mean_mrr:0.6216,ndcg@2:0.5568,ndcg@6:0.7159,ndcg@10:0.7159,group_auc:0.6962\n",
      "step 20 , total_loss: 1.3780, data_loss: 1.3780\n",
      "step 40 , total_loss: 1.3344, data_loss: 1.3344\n",
      "eval valid at epoch 6: auc:0.7105,logloss:0.5401,mean_mrr:0.6292,ndcg@2:0.5676,ndcg@6:0.7217,ndcg@10:0.7217,group_auc:0.7036\n",
      "step 20 , total_loss: 1.3871, data_loss: 1.3871\n",
      "step 40 , total_loss: 1.2887, data_loss: 1.2887\n",
      "eval valid at epoch 7: auc:0.7131,logloss:0.5341,mean_mrr:0.6334,ndcg@2:0.5746,ndcg@6:0.7248,ndcg@10:0.7248,group_auc:0.7054\n",
      "step 20 , total_loss: 1.3052, data_loss: 1.3052\n",
      "step 40 , total_loss: 1.2780, data_loss: 1.2780\n",
      "eval valid at epoch 8: auc:0.7152,logloss:0.5431,mean_mrr:0.6347,ndcg@2:0.5756,ndcg@6:0.7258,ndcg@10:0.7258,group_auc:0.7066\n",
      "step 20 , total_loss: 1.3028, data_loss: 1.3028\n",
      "step 40 , total_loss: 1.2722, data_loss: 1.2722\n",
      "eval valid at epoch 9: auc:0.7203,logloss:0.5257,mean_mrr:0.6408,ndcg@2:0.5834,ndcg@6:0.7304,ndcg@10:0.7304,group_auc:0.713\n",
      "step 20 , total_loss: 1.1785, data_loss: 1.1785\n",
      "step 40 , total_loss: 1.2506, data_loss: 1.2506\n",
      "eval valid at epoch 10: auc:0.7186,logloss:0.5339,mean_mrr:0.6429,ndcg@2:0.5831,ndcg@6:0.7319,ndcg@10:0.7319,group_auc:0.7129\n",
      "[(1, {'auc': 0.4953, 'logloss': 0.6931, 'mean_mrr': 0.4511, 'ndcg@2': 0.3177, 'ndcg@6': 0.5855, 'ndcg@10': 0.5855, 'group_auc': 0.4945}), (2, {'auc': 0.5057, 'logloss': 0.6889, 'mean_mrr': 0.4558, 'ndcg@2': 0.3259, 'ndcg@6': 0.5889, 'ndcg@10': 0.5889, 'group_auc': 0.4959}), (3, {'auc': 0.6579, 'logloss': 0.6493, 'mean_mrr': 0.57, 'ndcg@2': 0.4862, 'ndcg@6': 0.6768, 'ndcg@10': 0.6768, 'group_auc': 0.6438}), (4, {'auc': 0.6847, 'logloss': 0.5602, 'mean_mrr': 0.603, 'ndcg@2': 0.5344, 'ndcg@6': 0.702, 'ndcg@10': 0.702, 'group_auc': 0.6812}), (5, {'auc': 0.6954, 'logloss': 0.5262, 'mean_mrr': 0.6216, 'ndcg@2': 0.5568, 'ndcg@6': 0.7159, 'ndcg@10': 0.7159, 'group_auc': 0.6962}), (6, {'auc': 0.7105, 'logloss': 0.5401, 'mean_mrr': 0.6292, 'ndcg@2': 0.5676, 'ndcg@6': 0.7217, 'ndcg@10': 0.7217, 'group_auc': 0.7036}), (7, {'auc': 0.7131, 'logloss': 0.5341, 'mean_mrr': 0.6334, 'ndcg@2': 0.5746, 'ndcg@6': 0.7248, 'ndcg@10': 0.7248, 'group_auc': 0.7054}), (8, {'auc': 0.7152, 'logloss': 0.5431, 'mean_mrr': 0.6347, 'ndcg@2': 0.5756, 'ndcg@6': 0.7258, 'ndcg@10': 0.7258, 'group_auc': 0.7066}), (9, {'auc': 0.7203, 'logloss': 0.5257, 'mean_mrr': 0.6408, 'ndcg@2': 0.5834, 'ndcg@6': 0.7304, 'ndcg@10': 0.7304, 'group_auc': 0.713}), (10, {'auc': 0.7186, 'logloss': 0.5339, 'mean_mrr': 0.6429, 'ndcg@2': 0.5831, 'ndcg@6': 0.7319, 'ndcg@10': 0.7319, 'group_auc': 0.7129})]\n",
      "best epoch: 9\n",
      "Time cost for training is 1.83 mins\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    if os.path.exists(\"./model/asvd/\"):\n",
    "        model_path = os.path.join(\"./model/asvd/\", \"best_model\")\n",
    "        model.load_model(model_path)\n",
    "    else:\n",
    "        model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs) \n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# a2svd_training_result = []\n",
    "# for i in range(EPOCHS):\n",
    "#     epoch_model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
    "#     model_path = os.path.join(\"./model/asvd\", \"epoch_\" + str(i + 1))\n",
    "#     epoch_model.load_model(model_path)\n",
    "#     print('loading saved model in {0}'.format(model_path))\n",
    "#     a2svd_training_result.append((i + 1, epoch_model.run_eval(valid_file, num_ngs=valid_num_ngs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.6884,\n",
       " 'logloss': 0.5128,\n",
       " 'mean_mrr': 0.4601,\n",
       " 'ndcg@2': 0.3656,\n",
       " 'ndcg@6': 0.5227,\n",
       " 'ndcg@10': 0.587,\n",
       " 'group_auc': 0.68}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2svd_test_result_after_training = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "a2svd_test_result_after_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caser Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J. Tang and K. Wang, \"Personalized top-n sequential recommendation via convolutional sequence embedding\", in Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, ACM, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = './caser.yaml'\n",
    "hparams = prepare_hparams(\n",
    "    yaml_file,\n",
    "    embed_l2=0.,\n",
    "    layer_l2=0., \n",
    "    learning_rate=0.001,  # set to 0.01 if batch normalization is disable\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_step=20,\n",
    "    user_vocab=user_vocab,\n",
    "    item_vocab=item_vocab,\n",
    "    cate_vocab=cate_vocab,\n",
    "    need_sample=True,\n",
    "    train_num_ngs=train_num_ngs, # provides the number of negative instances for each positive instance for loss computation.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel\n",
    "model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.4918,\n",
       " 'logloss': 0.6931,\n",
       " 'mean_mrr': 0.2718,\n",
       " 'ndcg@2': 0.141,\n",
       " 'ndcg@6': 0.3033,\n",
       " 'ndcg@10': 0.4374,\n",
       " 'group_auc': 0.4911}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caser_test_result_before_training = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "caser_test_result_before_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20 , total_loss: 1.6100, data_loss: 1.6100\n",
      "eval valid at epoch 1: auc:0.4957,logloss:0.6929,mean_mrr:0.4503,ndcg@2:0.3156,ndcg@6:0.5849,ndcg@10:0.5849,group_auc:0.4959\n",
      "step 20 , total_loss: 1.5630, data_loss: 1.5630\n",
      "eval valid at epoch 2: auc:0.5943,logloss:0.692,mean_mrr:0.5262,ndcg@2:0.4194,ndcg@6:0.643,ndcg@10:0.643,group_auc:0.5853\n",
      "step 20 , total_loss: 1.4401, data_loss: 1.4401\n",
      "eval valid at epoch 3: auc:0.6365,logloss:0.6949,mean_mrr:0.5655,ndcg@2:0.4807,ndcg@6:0.6732,ndcg@10:0.6732,group_auc:0.6354\n",
      "step 20 , total_loss: 1.3128, data_loss: 1.3128\n",
      "eval valid at epoch 4: auc:0.6321,logloss:0.7347,mean_mrr:0.5664,ndcg@2:0.4765,ndcg@6:0.6737,ndcg@10:0.6737,group_auc:0.6333\n",
      "step 20 , total_loss: 1.2964, data_loss: 1.2964\n",
      "eval valid at epoch 5: auc:0.6661,logloss:0.7785,mean_mrr:0.5975,ndcg@2:0.526,ndcg@6:0.6975,ndcg@10:0.6975,group_auc:0.6685\n",
      "step 20 , total_loss: 1.1570, data_loss: 1.1570\n",
      "eval valid at epoch 6: auc:0.6821,logloss:0.7907,mean_mrr:0.6071,ndcg@2:0.529,ndcg@6:0.7046,ndcg@10:0.7046,group_auc:0.6731\n",
      "step 20 , total_loss: 1.1413, data_loss: 1.1413\n",
      "eval valid at epoch 7: auc:0.7365,logloss:0.6252,mean_mrr:0.66,ndcg@2:0.6093,ndcg@6:0.7449,ndcg@10:0.7449,group_auc:0.7304\n",
      "step 20 , total_loss: 1.1387, data_loss: 1.1387\n",
      "eval valid at epoch 8: auc:0.7233,logloss:0.6161,mean_mrr:0.6402,ndcg@2:0.5791,ndcg@6:0.7299,ndcg@10:0.7299,group_auc:0.7121\n",
      "step 20 , total_loss: 1.1518, data_loss: 1.1518\n",
      "eval valid at epoch 9: auc:0.7259,logloss:0.7527,mean_mrr:0.6389,ndcg@2:0.5771,ndcg@6:0.729,ndcg@10:0.729,group_auc:0.7121\n",
      "step 20 , total_loss: 1.0972, data_loss: 1.0972\n",
      "eval valid at epoch 10: auc:0.7378,logloss:0.6578,mean_mrr:0.6607,ndcg@2:0.6016,ndcg@6:0.7454,ndcg@10:0.7454,group_auc:0.7302\n",
      "[(1, {'auc': 0.4957, 'logloss': 0.6929, 'mean_mrr': 0.4503, 'ndcg@2': 0.3156, 'ndcg@6': 0.5849, 'ndcg@10': 0.5849, 'group_auc': 0.4959}), (2, {'auc': 0.5943, 'logloss': 0.692, 'mean_mrr': 0.5262, 'ndcg@2': 0.4194, 'ndcg@6': 0.643, 'ndcg@10': 0.643, 'group_auc': 0.5853}), (3, {'auc': 0.6365, 'logloss': 0.6949, 'mean_mrr': 0.5655, 'ndcg@2': 0.4807, 'ndcg@6': 0.6732, 'ndcg@10': 0.6732, 'group_auc': 0.6354}), (4, {'auc': 0.6321, 'logloss': 0.7347, 'mean_mrr': 0.5664, 'ndcg@2': 0.4765, 'ndcg@6': 0.6737, 'ndcg@10': 0.6737, 'group_auc': 0.6333}), (5, {'auc': 0.6661, 'logloss': 0.7785, 'mean_mrr': 0.5975, 'ndcg@2': 0.526, 'ndcg@6': 0.6975, 'ndcg@10': 0.6975, 'group_auc': 0.6685}), (6, {'auc': 0.6821, 'logloss': 0.7907, 'mean_mrr': 0.6071, 'ndcg@2': 0.529, 'ndcg@6': 0.7046, 'ndcg@10': 0.7046, 'group_auc': 0.6731}), (7, {'auc': 0.7365, 'logloss': 0.6252, 'mean_mrr': 0.66, 'ndcg@2': 0.6093, 'ndcg@6': 0.7449, 'ndcg@10': 0.7449, 'group_auc': 0.7304}), (8, {'auc': 0.7233, 'logloss': 0.6161, 'mean_mrr': 0.6402, 'ndcg@2': 0.5791, 'ndcg@6': 0.7299, 'ndcg@10': 0.7299, 'group_auc': 0.7121}), (9, {'auc': 0.7259, 'logloss': 0.7527, 'mean_mrr': 0.6389, 'ndcg@2': 0.5771, 'ndcg@6': 0.729, 'ndcg@10': 0.729, 'group_auc': 0.7121}), (10, {'auc': 0.7378, 'logloss': 0.6578, 'mean_mrr': 0.6607, 'ndcg@2': 0.6016, 'ndcg@6': 0.7454, 'ndcg@10': 0.7454, 'group_auc': 0.7302})]\n",
      "best epoch: 7\n",
      "Time cost for training is 1.76 mins\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    if os.path.exists(\"./model/caser/\"):\n",
    "        model_path = os.path.join(\"./model/caser/\", \"best_model\")\n",
    "        model.load_model(model_path)\n",
    "    else:\n",
    "        model = model.fit(train_file, valid_file, valid_num_ngs=valid_num_ngs)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# caser_training_result = []\n",
    "# for i in range(EPOCHS):\n",
    "#     epoch_model = SeqModel(hparams, input_creator, seed=RANDOM_SEED)\n",
    "#     model_path = os.path.join(\"./model/caser/\", \"epoch_\" + str(i + 1))\n",
    "#     epoch_model.load_model(model_path)\n",
    "#     print('loading saved model in {0}'.format(model_path))\n",
    "#     sli_rec_training_result.append((i + 1, epoch_model.run_eval(valid_file, num_ngs=valid_num_ngs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.6962,\n",
       " 'logloss': 0.6784,\n",
       " 'mean_mrr': 0.4646,\n",
       " 'ndcg@2': 0.3702,\n",
       " 'ndcg@6': 0.5276,\n",
       " 'ndcg@10': 0.5906,\n",
       " 'group_auc': 0.686}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caser_test_result_after_training = model.run_eval(test_file, num_ngs=test_num_ngs)\n",
    "caser_test_result_after_training"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcf1d46d271c46101d6967829d4a5f475342a2ce08e4944f989fbcdc9bb23690"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
