{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_SVD import my_SVD\n",
    "from funk_svd import SVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../../Data/Review Sample/\"\n",
    "\n",
    "train = pd.read_csv(dir + \"train_100k.csv\", on_bad_lines=\"skip\")\n",
    "valid = pd.read_csv(dir + \"validation_100k.csv\", on_bad_lines=\"skip\")\n",
    "test = pd.read_csv(dir + \"test_100k.csv\", on_bad_lines=\"skip\")\n",
    "\n",
    "input_train = train[['reviewerID', 'asin', 'overall']].rename(columns={\"reviewerID\": \"u_id\", \"asin\": \"i_id\", \"overall\": \"rating\"})\n",
    "input_valid = valid[['reviewerID', 'asin', 'overall']].rename(columns={\"reviewerID\": \"u_id\", \"asin\": \"i_id\", \"overall\": \"rating\"})\n",
    "input_test = test[['reviewerID', 'asin', 'overall']].rename(columns={\"reviewerID\": \"u_id\", \"asin\": \"i_id\", \"overall\": \"rating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_train = pd.read_csv(\"../../Data/NLP/train.csv\")[['reviewerID', 'asin', 'textRate']].rename(columns={\"reviewerID\": \"u_id\", \"asin\": \"i_id\", \"textRate\": \"nlp rating\"})\n",
    "nlp_valid = pd.read_csv(\"../../Data/NLP/validation.csv\")[['reviewerID', 'asin', 'textRate']].rename(columns={\"reviewerID\": \"u_id\", \"asin\": \"i_id\", \"textRate\": \"nlp rating\"})\n",
    "nlp_test = pd.read_csv(\"../../Data/NLP/test.csv\")[['reviewerID', 'asin', 'textRate']].rename(columns={\"reviewerID\": \"u_id\", \"asin\": \"i_id\", \"textRate\": \"nlp rating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train['nlp rating'] = nlp_train['nlp rating']\n",
    "input_valid['nlp rating'] = nlp_test['nlp rating']\n",
    "input_test['nlp rating'] = nlp_test['nlp rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "reg = 0.005\n",
    "n_epochs = 100\n",
    "n_factors = 5\n",
    "early_stopping = True\n",
    "shuffle = True\n",
    "min_rating = 1\n",
    "max_rating = 5\n",
    "min_delta = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_svd = my_SVD(lr=lr, reg=reg, n_epochs=n_epochs, n_factors=n_factors, early_stopping=early_stopping, shuffle=shuffle, min_rating=min_rating, max_rating=max_rating, min_delta=min_delta, mode=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | train_loss: 1.215 - train_rmse: 1.102 - train_mae: 0.859 - val_loss: 1.216 - val_rmse: 1.103 - val_mae: 0.861 - took 2.2 sec\n",
      "Epoch 2/100  | train_loss: 1.177 - train_rmse: 1.085 - train_mae: 0.845 - val_loss: 1.196 - val_rmse: 1.094 - val_mae: 0.852 - took 1.1 sec\n",
      "Epoch 3/100  | train_loss: 1.146 - train_rmse: 1.070 - train_mae: 0.834 - val_loss: 1.180 - val_rmse: 1.086 - val_mae: 0.844 - took 1.0 sec\n",
      "Epoch 4/100  | train_loss: 1.118 - train_rmse: 1.057 - train_mae: 0.823 - val_loss: 1.167 - val_rmse: 1.080 - val_mae: 0.838 - took 0.9 sec\n",
      "Epoch 5/100  | train_loss: 1.093 - train_rmse: 1.045 - train_mae: 0.814 - val_loss: 1.156 - val_rmse: 1.075 - val_mae: 0.832 - took 1.0 sec\n",
      "Epoch 6/100  | train_loss: 1.070 - train_rmse: 1.034 - train_mae: 0.805 - val_loss: 1.147 - val_rmse: 1.071 - val_mae: 0.827 - took 0.9 sec\n",
      "Epoch 7/100  | train_loss: 1.050 - train_rmse: 1.024 - train_mae: 0.796 - val_loss: 1.139 - val_rmse: 1.067 - val_mae: 0.823 - took 1.0 sec\n",
      "Epoch 8/100  | train_loss: 1.031 - train_rmse: 1.015 - train_mae: 0.789 - val_loss: 1.133 - val_rmse: 1.064 - val_mae: 0.819 - took 1.0 sec\n",
      "Epoch 9/100  | train_loss: 1.013 - train_rmse: 1.006 - train_mae: 0.781 - val_loss: 1.127 - val_rmse: 1.061 - val_mae: 0.815 - took 0.9 sec\n",
      "Epoch 10/100 | train_loss: 0.997 - train_rmse: 0.998 - train_mae: 0.775 - val_loss: 1.121 - val_rmse: 1.059 - val_mae: 0.812 - took 0.9 sec\n",
      "Epoch 11/100 | train_loss: 0.981 - train_rmse: 0.991 - train_mae: 0.768 - val_loss: 1.117 - val_rmse: 1.057 - val_mae: 0.809 - took 0.9 sec\n",
      "Epoch 12/100 | train_loss: 0.967 - train_rmse: 0.983 - train_mae: 0.762 - val_loss: 1.113 - val_rmse: 1.055 - val_mae: 0.806 - took 0.9 sec\n",
      "Epoch 13/100 | train_loss: 0.953 - train_rmse: 0.976 - train_mae: 0.756 - val_loss: 1.109 - val_rmse: 1.053 - val_mae: 0.803 - took 1.0 sec\n",
      "Epoch 14/100 | train_loss: 0.941 - train_rmse: 0.970 - train_mae: 0.750 - val_loss: 1.106 - val_rmse: 1.052 - val_mae: 0.801 - took 1.0 sec\n",
      "Epoch 15/100 | train_loss: 0.929 - train_rmse: 0.964 - train_mae: 0.745 - val_loss: 1.104 - val_rmse: 1.051 - val_mae: 0.799 - took 0.9 sec\n",
      "Epoch 16/100 | train_loss: 0.917 - train_rmse: 0.958 - train_mae: 0.740 - val_loss: 1.101 - val_rmse: 1.049 - val_mae: 0.796 - took 1.0 sec\n",
      "Epoch 17/100 | train_loss: 0.906 - train_rmse: 0.952 - train_mae: 0.735 - val_loss: 1.099 - val_rmse: 1.048 - val_mae: 0.794 - took 0.9 sec\n",
      "Epoch 18/100 | train_loss: 0.896 - train_rmse: 0.947 - train_mae: 0.730 - val_loss: 1.097 - val_rmse: 1.047 - val_mae: 0.792 - took 0.9 sec\n",
      "Epoch 19/100 | train_loss: 0.886 - train_rmse: 0.941 - train_mae: 0.725 - val_loss: 1.095 - val_rmse: 1.047 - val_mae: 0.791 - took 1.1 sec\n",
      "Epoch 20/100 | train_loss: 0.876 - train_rmse: 0.936 - train_mae: 0.721 - val_loss: 1.094 - val_rmse: 1.046 - val_mae: 0.789 - took 1.0 sec\n",
      "Epoch 21/100 | train_loss: 0.867 - train_rmse: 0.931 - train_mae: 0.716 - val_loss: 1.093 - val_rmse: 1.045 - val_mae: 0.787 - took 0.9 sec\n",
      "Epoch 22/100 | train_loss: 0.859 - train_rmse: 0.927 - train_mae: 0.712 - val_loss: 1.091 - val_rmse: 1.045 - val_mae: 0.786 - took 0.9 sec\n",
      "Epoch 23/100 | train_loss: 0.850 - train_rmse: 0.922 - train_mae: 0.708 - val_loss: 1.090 - val_rmse: 1.044 - val_mae: 0.784 - took 1.0 sec\n",
      "Epoch 24/100 | train_loss: 0.842 - train_rmse: 0.918 - train_mae: 0.704 - val_loss: 1.090 - val_rmse: 1.044 - val_mae: 0.783 - took 0.9 sec\n",
      "Epoch 25/100 | train_loss: 0.835 - train_rmse: 0.914 - train_mae: 0.701 - val_loss: 1.089 - val_rmse: 1.043 - val_mae: 0.781 - took 0.9 sec\n",
      "Epoch 26/100 | train_loss: 0.827 - train_rmse: 0.909 - train_mae: 0.697 - val_loss: 1.088 - val_rmse: 1.043 - val_mae: 0.780 - took 0.9 sec\n",
      "Epoch 27/100 | train_loss: 0.820 - train_rmse: 0.905 - train_mae: 0.693 - val_loss: 1.088 - val_rmse: 1.043 - val_mae: 0.779 - took 0.9 sec\n",
      "Epoch 28/100 | train_loss: 0.813 - train_rmse: 0.902 - train_mae: 0.690 - val_loss: 1.087 - val_rmse: 1.043 - val_mae: 0.778 - took 0.9 sec\n",
      "Epoch 29/100 | train_loss: 0.806 - train_rmse: 0.898 - train_mae: 0.686 - val_loss: 1.087 - val_rmse: 1.042 - val_mae: 0.777 - took 0.9 sec\n",
      "Epoch 30/100 | train_loss: 0.800 - train_rmse: 0.894 - train_mae: 0.683 - val_loss: 1.086 - val_rmse: 1.042 - val_mae: 0.775 - took 0.9 sec\n",
      "Epoch 31/100 | train_loss: 0.794 - train_rmse: 0.891 - train_mae: 0.680 - val_loss: 1.086 - val_rmse: 1.042 - val_mae: 0.774 - took 1.0 sec\n",
      "Epoch 32/100 | train_loss: 0.787 - train_rmse: 0.887 - train_mae: 0.677 - val_loss: 1.086 - val_rmse: 1.042 - val_mae: 0.773 - took 0.9 sec\n",
      "\n",
      "Training took 37 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<my_SVD.my_SVD at 0x274c176b3a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_svd.fit(input_train, input_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Valid Loss</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.214811</td>\n",
       "      <td>1.102185</td>\n",
       "      <td>0.859108</td>\n",
       "      <td>1.216104</td>\n",
       "      <td>1.102771</td>\n",
       "      <td>0.860615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.177262</td>\n",
       "      <td>1.085017</td>\n",
       "      <td>0.845484</td>\n",
       "      <td>1.195744</td>\n",
       "      <td>1.093501</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.145510</td>\n",
       "      <td>1.070285</td>\n",
       "      <td>0.833681</td>\n",
       "      <td>1.179940</td>\n",
       "      <td>1.086250</td>\n",
       "      <td>0.844243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.117650</td>\n",
       "      <td>1.057190</td>\n",
       "      <td>0.823120</td>\n",
       "      <td>1.167032</td>\n",
       "      <td>1.080293</td>\n",
       "      <td>0.837924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.092742</td>\n",
       "      <td>1.045343</td>\n",
       "      <td>0.813508</td>\n",
       "      <td>1.156256</td>\n",
       "      <td>1.075293</td>\n",
       "      <td>0.832408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.070187</td>\n",
       "      <td>1.034498</td>\n",
       "      <td>0.804631</td>\n",
       "      <td>1.147111</td>\n",
       "      <td>1.071033</td>\n",
       "      <td>0.827485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.049575</td>\n",
       "      <td>1.024488</td>\n",
       "      <td>0.796383</td>\n",
       "      <td>1.139280</td>\n",
       "      <td>1.067371</td>\n",
       "      <td>0.823066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.030598</td>\n",
       "      <td>1.015183</td>\n",
       "      <td>0.788645</td>\n",
       "      <td>1.132503</td>\n",
       "      <td>1.064191</td>\n",
       "      <td>0.819045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.013019</td>\n",
       "      <td>1.006488</td>\n",
       "      <td>0.781375</td>\n",
       "      <td>1.126614</td>\n",
       "      <td>1.061421</td>\n",
       "      <td>0.815395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.996657</td>\n",
       "      <td>0.998327</td>\n",
       "      <td>0.774511</td>\n",
       "      <td>1.121462</td>\n",
       "      <td>1.058991</td>\n",
       "      <td>0.812047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.981355</td>\n",
       "      <td>0.990634</td>\n",
       "      <td>0.767991</td>\n",
       "      <td>1.116943</td>\n",
       "      <td>1.056855</td>\n",
       "      <td>0.808948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.966998</td>\n",
       "      <td>0.983360</td>\n",
       "      <td>0.761799</td>\n",
       "      <td>1.112953</td>\n",
       "      <td>1.054966</td>\n",
       "      <td>0.806077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.953480</td>\n",
       "      <td>0.976463</td>\n",
       "      <td>0.755905</td>\n",
       "      <td>1.109451</td>\n",
       "      <td>1.053305</td>\n",
       "      <td>0.803429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.940714</td>\n",
       "      <td>0.969904</td>\n",
       "      <td>0.750261</td>\n",
       "      <td>1.106351</td>\n",
       "      <td>1.051832</td>\n",
       "      <td>0.800942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.928629</td>\n",
       "      <td>0.963654</td>\n",
       "      <td>0.744858</td>\n",
       "      <td>1.103606</td>\n",
       "      <td>1.050526</td>\n",
       "      <td>0.798617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.917162</td>\n",
       "      <td>0.957686</td>\n",
       "      <td>0.739665</td>\n",
       "      <td>1.101151</td>\n",
       "      <td>1.049357</td>\n",
       "      <td>0.796411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.906258</td>\n",
       "      <td>0.951976</td>\n",
       "      <td>0.734690</td>\n",
       "      <td>1.098999</td>\n",
       "      <td>1.048331</td>\n",
       "      <td>0.794361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.895868</td>\n",
       "      <td>0.946503</td>\n",
       "      <td>0.729893</td>\n",
       "      <td>1.097097</td>\n",
       "      <td>1.047424</td>\n",
       "      <td>0.792420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.885949</td>\n",
       "      <td>0.941249</td>\n",
       "      <td>0.725268</td>\n",
       "      <td>1.095407</td>\n",
       "      <td>1.046617</td>\n",
       "      <td>0.790581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.876467</td>\n",
       "      <td>0.936198</td>\n",
       "      <td>0.720804</td>\n",
       "      <td>1.093914</td>\n",
       "      <td>1.045903</td>\n",
       "      <td>0.788846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.867388</td>\n",
       "      <td>0.931336</td>\n",
       "      <td>0.716493</td>\n",
       "      <td>1.092601</td>\n",
       "      <td>1.045276</td>\n",
       "      <td>0.787194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.858681</td>\n",
       "      <td>0.926651</td>\n",
       "      <td>0.712331</td>\n",
       "      <td>1.091435</td>\n",
       "      <td>1.044718</td>\n",
       "      <td>0.785634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.850322</td>\n",
       "      <td>0.922129</td>\n",
       "      <td>0.708295</td>\n",
       "      <td>1.090429</td>\n",
       "      <td>1.044236</td>\n",
       "      <td>0.784149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.917761</td>\n",
       "      <td>0.704379</td>\n",
       "      <td>1.089549</td>\n",
       "      <td>1.043815</td>\n",
       "      <td>0.782728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.834551</td>\n",
       "      <td>0.913538</td>\n",
       "      <td>0.700583</td>\n",
       "      <td>1.088782</td>\n",
       "      <td>1.043447</td>\n",
       "      <td>0.781370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.827100</td>\n",
       "      <td>0.909450</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>1.088131</td>\n",
       "      <td>1.043135</td>\n",
       "      <td>0.780078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.819912</td>\n",
       "      <td>0.905490</td>\n",
       "      <td>0.693328</td>\n",
       "      <td>1.087581</td>\n",
       "      <td>1.042872</td>\n",
       "      <td>0.778853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.812975</td>\n",
       "      <td>0.901651</td>\n",
       "      <td>0.689850</td>\n",
       "      <td>1.087133</td>\n",
       "      <td>1.042657</td>\n",
       "      <td>0.777679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.806271</td>\n",
       "      <td>0.897926</td>\n",
       "      <td>0.686471</td>\n",
       "      <td>1.086743</td>\n",
       "      <td>1.042470</td>\n",
       "      <td>0.776551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.799787</td>\n",
       "      <td>0.894308</td>\n",
       "      <td>0.683171</td>\n",
       "      <td>1.086445</td>\n",
       "      <td>1.042327</td>\n",
       "      <td>0.775467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.793512</td>\n",
       "      <td>0.890793</td>\n",
       "      <td>0.679966</td>\n",
       "      <td>1.086209</td>\n",
       "      <td>1.042213</td>\n",
       "      <td>0.774436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.787435</td>\n",
       "      <td>0.887375</td>\n",
       "      <td>0.676840</td>\n",
       "      <td>1.086052</td>\n",
       "      <td>1.042138</td>\n",
       "      <td>0.773450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Train Loss  Train RMSE  Train MAE  Valid Loss  Valid RMSE  Valid MAE\n",
       "0     1.214811    1.102185   0.859108    1.216104    1.102771   0.860615\n",
       "1     1.177262    1.085017   0.845484    1.195744    1.093501   0.851632\n",
       "2     1.145510    1.070285   0.833681    1.179940    1.086250   0.844243\n",
       "3     1.117650    1.057190   0.823120    1.167032    1.080293   0.837924\n",
       "4     1.092742    1.045343   0.813508    1.156256    1.075293   0.832408\n",
       "5     1.070187    1.034498   0.804631    1.147111    1.071033   0.827485\n",
       "6     1.049575    1.024488   0.796383    1.139280    1.067371   0.823066\n",
       "7     1.030598    1.015183   0.788645    1.132503    1.064191   0.819045\n",
       "8     1.013019    1.006488   0.781375    1.126614    1.061421   0.815395\n",
       "9     0.996657    0.998327   0.774511    1.121462    1.058991   0.812047\n",
       "10    0.981355    0.990634   0.767991    1.116943    1.056855   0.808948\n",
       "11    0.966998    0.983360   0.761799    1.112953    1.054966   0.806077\n",
       "12    0.953480    0.976463   0.755905    1.109451    1.053305   0.803429\n",
       "13    0.940714    0.969904   0.750261    1.106351    1.051832   0.800942\n",
       "14    0.928629    0.963654   0.744858    1.103606    1.050526   0.798617\n",
       "15    0.917162    0.957686   0.739665    1.101151    1.049357   0.796411\n",
       "16    0.906258    0.951976   0.734690    1.098999    1.048331   0.794361\n",
       "17    0.895868    0.946503   0.729893    1.097097    1.047424   0.792420\n",
       "18    0.885949    0.941249   0.725268    1.095407    1.046617   0.790581\n",
       "19    0.876467    0.936198   0.720804    1.093914    1.045903   0.788846\n",
       "20    0.867388    0.931336   0.716493    1.092601    1.045276   0.787194\n",
       "21    0.858681    0.926651   0.712331    1.091435    1.044718   0.785634\n",
       "22    0.850322    0.922129   0.708295    1.090429    1.044236   0.784149\n",
       "23    0.842286    0.917761   0.704379    1.089549    1.043815   0.782728\n",
       "24    0.834551    0.913538   0.700583    1.088782    1.043447   0.781370\n",
       "25    0.827100    0.909450   0.696900    1.088131    1.043135   0.780078\n",
       "26    0.819912    0.905490   0.693328    1.087581    1.042872   0.778853\n",
       "27    0.812975    0.901651   0.689850    1.087133    1.042657   0.777679\n",
       "28    0.806271    0.897926   0.686471    1.086743    1.042470   0.776551\n",
       "29    0.799787    0.894308   0.683171    1.086445    1.042327   0.775467\n",
       "30    0.793512    0.890793   0.679966    1.086209    1.042213   0.774436\n",
       "31    0.787435    0.887375   0.676840    1.086052    1.042138   0.773450\n",
       "32    0.000000    0.000000   0.000000    0.000000    0.000000   0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_svd.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating only SVD RMSE on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1141685425274706"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rating_svd.predict(input_test)\n",
    "rmse = sqrt(mean_squared_error(input_test['rating'], np.array(pred)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating + NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_nlp_svd = my_SVD(lr=lr, reg=reg, n_epochs=n_epochs, n_factors=n_factors, early_stopping=early_stopping, shuffle=shuffle, min_rating=min_rating, max_rating=max_rating, min_delta=min_delta, mode=\"mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | train_loss: 1.196 - train_rmse: 1.094 - train_mae: 0.854 - val_loss: 1.208 - val_rmse: 1.099 - val_mae: 0.858 - took 1.9 sec\n",
      "Epoch 2/100  | train_loss: 1.146 - train_rmse: 1.071 - train_mae: 0.837 - val_loss: 1.184 - val_rmse: 1.088 - val_mae: 0.848 - took 1.0 sec\n",
      "Epoch 3/100  | train_loss: 1.106 - train_rmse: 1.052 - train_mae: 0.823 - val_loss: 1.166 - val_rmse: 1.080 - val_mae: 0.840 - took 1.0 sec\n",
      "Epoch 4/100  | train_loss: 1.071 - train_rmse: 1.035 - train_mae: 0.810 - val_loss: 1.152 - val_rmse: 1.074 - val_mae: 0.834 - took 1.0 sec\n",
      "Epoch 5/100  | train_loss: 1.040 - train_rmse: 1.020 - train_mae: 0.799 - val_loss: 1.142 - val_rmse: 1.068 - val_mae: 0.828 - took 1.0 sec\n",
      "Epoch 6/100  | train_loss: 1.013 - train_rmse: 1.007 - train_mae: 0.788 - val_loss: 1.133 - val_rmse: 1.064 - val_mae: 0.823 - took 1.0 sec\n",
      "Epoch 7/100  | train_loss: 0.989 - train_rmse: 0.994 - train_mae: 0.778 - val_loss: 1.126 - val_rmse: 1.061 - val_mae: 0.818 - took 1.0 sec\n",
      "Epoch 8/100  | train_loss: 0.967 - train_rmse: 0.983 - train_mae: 0.769 - val_loss: 1.120 - val_rmse: 1.058 - val_mae: 0.814 - took 1.0 sec\n",
      "Epoch 9/100  | train_loss: 0.946 - train_rmse: 0.973 - train_mae: 0.761 - val_loss: 1.115 - val_rmse: 1.056 - val_mae: 0.811 - took 1.0 sec\n",
      "Epoch 10/100 | train_loss: 0.928 - train_rmse: 0.963 - train_mae: 0.753 - val_loss: 1.111 - val_rmse: 1.054 - val_mae: 0.808 - took 1.0 sec\n",
      "Epoch 11/100 | train_loss: 0.911 - train_rmse: 0.954 - train_mae: 0.745 - val_loss: 1.107 - val_rmse: 1.052 - val_mae: 0.805 - took 1.0 sec\n",
      "Epoch 12/100 | train_loss: 0.895 - train_rmse: 0.946 - train_mae: 0.738 - val_loss: 1.105 - val_rmse: 1.051 - val_mae: 0.802 - took 1.0 sec\n",
      "Epoch 13/100 | train_loss: 0.880 - train_rmse: 0.938 - train_mae: 0.731 - val_loss: 1.102 - val_rmse: 1.050 - val_mae: 0.799 - took 1.1 sec\n",
      "Epoch 14/100 | train_loss: 0.866 - train_rmse: 0.931 - train_mae: 0.725 - val_loss: 1.100 - val_rmse: 1.049 - val_mae: 0.797 - took 1.0 sec\n",
      "Epoch 15/100 | train_loss: 0.853 - train_rmse: 0.923 - train_mae: 0.719 - val_loss: 1.098 - val_rmse: 1.048 - val_mae: 0.795 - took 1.1 sec\n",
      "Epoch 16/100 | train_loss: 0.841 - train_rmse: 0.917 - train_mae: 0.713 - val_loss: 1.097 - val_rmse: 1.047 - val_mae: 0.793 - took 1.1 sec\n",
      "Epoch 17/100 | train_loss: 0.829 - train_rmse: 0.910 - train_mae: 0.707 - val_loss: 1.096 - val_rmse: 1.047 - val_mae: 0.791 - took 1.1 sec\n",
      "Epoch 18/100 | train_loss: 0.818 - train_rmse: 0.904 - train_mae: 0.702 - val_loss: 1.095 - val_rmse: 1.047 - val_mae: 0.789 - took 1.1 sec\n",
      "Epoch 19/100 | train_loss: 0.808 - train_rmse: 0.899 - train_mae: 0.696 - val_loss: 1.095 - val_rmse: 1.046 - val_mae: 0.787 - took 1.1 sec\n",
      "Epoch 20/100 | train_loss: 0.798 - train_rmse: 0.893 - train_mae: 0.691 - val_loss: 1.094 - val_rmse: 1.046 - val_mae: 0.785 - took 1.0 sec\n",
      "Epoch 21/100 | train_loss: 0.788 - train_rmse: 0.888 - train_mae: 0.687 - val_loss: 1.094 - val_rmse: 1.046 - val_mae: 0.784 - took 1.0 sec\n",
      "Epoch 22/100 | train_loss: 0.779 - train_rmse: 0.883 - train_mae: 0.682 - val_loss: 1.093 - val_rmse: 1.046 - val_mae: 0.782 - took 1.0 sec\n",
      "\n",
      "Training took 29 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<my_SVD.my_SVD at 0x2753736dca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_nlp_svd.fit(input_train, input_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Valid Loss</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.196055</td>\n",
       "      <td>1.093643</td>\n",
       "      <td>0.854355</td>\n",
       "      <td>1.207696</td>\n",
       "      <td>1.098952</td>\n",
       "      <td>0.858336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.146457</td>\n",
       "      <td>1.070727</td>\n",
       "      <td>0.837414</td>\n",
       "      <td>1.183651</td>\n",
       "      <td>1.087957</td>\n",
       "      <td>0.848193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.105699</td>\n",
       "      <td>1.051522</td>\n",
       "      <td>0.822991</td>\n",
       "      <td>1.166036</td>\n",
       "      <td>1.079832</td>\n",
       "      <td>0.840183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.070837</td>\n",
       "      <td>1.034812</td>\n",
       "      <td>0.810216</td>\n",
       "      <td>1.152423</td>\n",
       "      <td>1.073510</td>\n",
       "      <td>0.833509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.040322</td>\n",
       "      <td>1.019962</td>\n",
       "      <td>0.798659</td>\n",
       "      <td>1.141619</td>\n",
       "      <td>1.068466</td>\n",
       "      <td>0.827791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.013201</td>\n",
       "      <td>1.006579</td>\n",
       "      <td>0.788097</td>\n",
       "      <td>1.132893</td>\n",
       "      <td>1.064374</td>\n",
       "      <td>0.822837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.988813</td>\n",
       "      <td>0.994391</td>\n",
       "      <td>0.778342</td>\n",
       "      <td>1.125732</td>\n",
       "      <td>1.061005</td>\n",
       "      <td>0.818431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966688</td>\n",
       "      <td>0.983203</td>\n",
       "      <td>0.769267</td>\n",
       "      <td>1.119832</td>\n",
       "      <td>1.058221</td>\n",
       "      <td>0.814492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.946463</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.760777</td>\n",
       "      <td>1.114918</td>\n",
       "      <td>1.055897</td>\n",
       "      <td>0.810931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.927864</td>\n",
       "      <td>0.963257</td>\n",
       "      <td>0.752777</td>\n",
       "      <td>1.110815</td>\n",
       "      <td>1.053952</td>\n",
       "      <td>0.807661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.910668</td>\n",
       "      <td>0.954289</td>\n",
       "      <td>0.745239</td>\n",
       "      <td>1.107381</td>\n",
       "      <td>1.052322</td>\n",
       "      <td>0.804672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.894703</td>\n",
       "      <td>0.945887</td>\n",
       "      <td>0.738109</td>\n",
       "      <td>1.104535</td>\n",
       "      <td>1.050968</td>\n",
       "      <td>0.801938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.879815</td>\n",
       "      <td>0.937985</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>1.102128</td>\n",
       "      <td>1.049823</td>\n",
       "      <td>0.799369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.865888</td>\n",
       "      <td>0.930531</td>\n",
       "      <td>0.724852</td>\n",
       "      <td>1.100122</td>\n",
       "      <td>1.048867</td>\n",
       "      <td>0.796982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.852820</td>\n",
       "      <td>0.923482</td>\n",
       "      <td>0.718683</td>\n",
       "      <td>1.098483</td>\n",
       "      <td>1.048085</td>\n",
       "      <td>0.794757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.840522</td>\n",
       "      <td>0.916800</td>\n",
       "      <td>0.712776</td>\n",
       "      <td>1.097140</td>\n",
       "      <td>1.047444</td>\n",
       "      <td>0.792676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.828921</td>\n",
       "      <td>0.910451</td>\n",
       "      <td>0.707105</td>\n",
       "      <td>1.096042</td>\n",
       "      <td>1.046920</td>\n",
       "      <td>0.790696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.817953</td>\n",
       "      <td>0.904408</td>\n",
       "      <td>0.701665</td>\n",
       "      <td>1.095184</td>\n",
       "      <td>1.046510</td>\n",
       "      <td>0.788848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.807563</td>\n",
       "      <td>0.898645</td>\n",
       "      <td>0.696448</td>\n",
       "      <td>1.094537</td>\n",
       "      <td>1.046201</td>\n",
       "      <td>0.787121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.797698</td>\n",
       "      <td>0.893140</td>\n",
       "      <td>0.691405</td>\n",
       "      <td>1.094037</td>\n",
       "      <td>1.045962</td>\n",
       "      <td>0.785459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.887875</td>\n",
       "      <td>0.686559</td>\n",
       "      <td>1.093690</td>\n",
       "      <td>1.045796</td>\n",
       "      <td>0.783894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.779389</td>\n",
       "      <td>0.882830</td>\n",
       "      <td>0.681871</td>\n",
       "      <td>1.093489</td>\n",
       "      <td>1.045700</td>\n",
       "      <td>0.782408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Train Loss  Train RMSE  Train MAE  Valid Loss  Valid RMSE  Valid MAE\n",
       "0     1.196055    1.093643   0.854355    1.207696    1.098952   0.858336\n",
       "1     1.146457    1.070727   0.837414    1.183651    1.087957   0.848193\n",
       "2     1.105699    1.051522   0.822991    1.166036    1.079832   0.840183\n",
       "3     1.070837    1.034812   0.810216    1.152423    1.073510   0.833509\n",
       "4     1.040322    1.019962   0.798659    1.141619    1.068466   0.827791\n",
       "5     1.013201    1.006579   0.788097    1.132893    1.064374   0.822837\n",
       "6     0.988813    0.994391   0.778342    1.125732    1.061005   0.818431\n",
       "7     0.966688    0.983203   0.769267    1.119832    1.058221   0.814492\n",
       "8     0.946463    0.972864   0.760777    1.114918    1.055897   0.810931\n",
       "9     0.927864    0.963257   0.752777    1.110815    1.053952   0.807661\n",
       "10    0.910668    0.954289   0.745239    1.107381    1.052322   0.804672\n",
       "11    0.894703    0.945887   0.738109    1.104535    1.050968   0.801938\n",
       "12    0.879815    0.937985   0.731315    1.102128    1.049823   0.799369\n",
       "13    0.865888    0.930531   0.724852    1.100122    1.048867   0.796982\n",
       "14    0.852820    0.923482   0.718683    1.098483    1.048085   0.794757\n",
       "15    0.840522    0.916800   0.712776    1.097140    1.047444   0.792676\n",
       "16    0.828921    0.910451   0.707105    1.096042    1.046920   0.790696\n",
       "17    0.817953    0.904408   0.701665    1.095184    1.046510   0.788848\n",
       "18    0.807563    0.898645   0.696448    1.094537    1.046201   0.787121\n",
       "19    0.797698    0.893140   0.691405    1.094037    1.045962   0.785459\n",
       "20    0.788321    0.887875   0.686559    1.093690    1.045796   0.783894\n",
       "21    0.779389    0.882830   0.681871    1.093489    1.045700   0.782408\n",
       "22    0.000000    0.000000   0.000000    0.000000    0.000000   0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_nlp_svd.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating + NLP SVD RMSE on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1204619430983174"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rating_nlp_svd.predict(input_test)\n",
    "rmse = sqrt(mean_squared_error(input_test['rating'], pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(lr=lr, reg=reg, n_epochs=n_epochs, n_factors=n_factors, early_stopping=early_stopping, shuffle=shuffle, min_rating=min_rating, max_rating=max_rating, min_delta=min_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | val_loss: 1.23 - val_rmse: 1.11 - val_mae: 0.86 - took 1.3 sec\n",
      "Epoch 2/100  | val_loss: 1.22 - val_rmse: 1.10 - val_mae: 0.86 - took 0.7 sec\n",
      "Epoch 3/100  | val_loss: 1.21 - val_rmse: 1.10 - val_mae: 0.85 - took 0.7 sec\n",
      "Epoch 4/100  | val_loss: 1.20 - val_rmse: 1.09 - val_mae: 0.85 - took 0.6 sec\n",
      "Epoch 5/100  | val_loss: 1.19 - val_rmse: 1.09 - val_mae: 0.84 - took 0.7 sec\n",
      "Epoch 6/100  | val_loss: 1.18 - val_rmse: 1.09 - val_mae: 0.84 - took 0.7 sec\n",
      "Epoch 7/100  | val_loss: 1.18 - val_rmse: 1.08 - val_mae: 0.83 - took 0.7 sec\n",
      "Epoch 8/100  | val_loss: 1.17 - val_rmse: 1.08 - val_mae: 0.83 - took 0.6 sec\n",
      "Epoch 9/100  | val_loss: 1.16 - val_rmse: 1.08 - val_mae: 0.83 - took 0.6 sec\n",
      "Epoch 10/100 | val_loss: 1.16 - val_rmse: 1.08 - val_mae: 0.82 - took 0.7 sec\n",
      "Epoch 11/100 | val_loss: 1.15 - val_rmse: 1.07 - val_mae: 0.82 - took 0.7 sec\n",
      "Epoch 12/100 | val_loss: 1.15 - val_rmse: 1.07 - val_mae: 0.82 - took 0.7 sec\n",
      "Epoch 13/100 | val_loss: 1.15 - val_rmse: 1.07 - val_mae: 0.81 - took 0.8 sec\n",
      "Epoch 14/100 | val_loss: 1.14 - val_rmse: 1.07 - val_mae: 0.81 - took 0.8 sec\n",
      "Epoch 15/100 | val_loss: 1.14 - val_rmse: 1.07 - val_mae: 0.81 - took 0.6 sec\n",
      "Epoch 16/100 | val_loss: 1.13 - val_rmse: 1.07 - val_mae: 0.81 - took 0.6 sec\n",
      "Epoch 17/100 | val_loss: 1.13 - val_rmse: 1.06 - val_mae: 0.81 - took 0.6 sec\n",
      "Epoch 18/100 | val_loss: 1.13 - val_rmse: 1.06 - val_mae: 0.80 - took 0.6 sec\n",
      "Epoch 19/100 | val_loss: 1.13 - val_rmse: 1.06 - val_mae: 0.80 - took 0.6 sec\n",
      "Epoch 20/100 | val_loss: 1.12 - val_rmse: 1.06 - val_mae: 0.80 - took 0.7 sec\n",
      "Epoch 21/100 | val_loss: 1.12 - val_rmse: 1.06 - val_mae: 0.80 - took 0.7 sec\n",
      "Epoch 22/100 | val_loss: 1.12 - val_rmse: 1.06 - val_mae: 0.80 - took 0.6 sec\n",
      "Epoch 23/100 | val_loss: 1.12 - val_rmse: 1.06 - val_mae: 0.79 - took 0.7 sec\n",
      "Epoch 24/100 | val_loss: 1.11 - val_rmse: 1.06 - val_mae: 0.79 - took 0.7 sec\n",
      "Epoch 25/100 | val_loss: 1.11 - val_rmse: 1.05 - val_mae: 0.79 - took 0.6 sec\n",
      "Epoch 26/100 | val_loss: 1.11 - val_rmse: 1.05 - val_mae: 0.79 - took 0.7 sec\n",
      "Epoch 27/100 | val_loss: 1.11 - val_rmse: 1.05 - val_mae: 0.79 - took 0.7 sec\n",
      "Epoch 28/100 | val_loss: 1.11 - val_rmse: 1.05 - val_mae: 0.79 - took 0.7 sec\n",
      "Epoch 29/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.79 - took 0.7 sec\n",
      "Epoch 30/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.6 sec\n",
      "Epoch 31/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.6 sec\n",
      "Epoch 32/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.7 sec\n",
      "Epoch 33/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.7 sec\n",
      "Epoch 34/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.6 sec\n",
      "Epoch 35/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.7 sec\n",
      "Epoch 36/100 | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.78 - took 0.7 sec\n",
      "Epoch 37/100 | val_loss: 1.09 - val_rmse: 1.05 - val_mae: 0.78 - took 0.6 sec\n",
      "Epoch 38/100 | val_loss: 1.09 - val_rmse: 1.05 - val_mae: 0.78 - took 0.7 sec\n",
      "Epoch 39/100 | val_loss: 1.09 - val_rmse: 1.05 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 40/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 41/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.6 sec\n",
      "Epoch 42/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 43/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 44/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 45/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 46/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.6 sec\n",
      "Epoch 47/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 48/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 49/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 50/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 51/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 52/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.77 - took 0.7 sec\n",
      "Epoch 53/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 54/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "Epoch 55/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "Epoch 56/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "Epoch 57/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 58/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "Epoch 59/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 60/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "Epoch 61/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 62/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "Epoch 63/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 64/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 65/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 66/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 67/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.6 sec\n",
      "Epoch 68/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.76 - took 0.7 sec\n",
      "\n",
      "Training took 49 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<funk_svd.svd.SVD at 0x27538e830a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit(X=input_train, X_val=input_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.230007</td>\n",
       "      <td>1.109057</td>\n",
       "      <td>0.864268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.217044</td>\n",
       "      <td>1.103197</td>\n",
       "      <td>0.857435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.206429</td>\n",
       "      <td>1.098375</td>\n",
       "      <td>0.851549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.197270</td>\n",
       "      <td>1.094198</td>\n",
       "      <td>0.846326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.189172</td>\n",
       "      <td>1.090491</td>\n",
       "      <td>0.841638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.078494</td>\n",
       "      <td>1.038506</td>\n",
       "      <td>0.758642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.078260</td>\n",
       "      <td>1.038393</td>\n",
       "      <td>0.758239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.078050</td>\n",
       "      <td>1.038292</td>\n",
       "      <td>0.757860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.077845</td>\n",
       "      <td>1.038193</td>\n",
       "      <td>0.757477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Loss      RMSE       MAE\n",
       "0   1.230007  1.109057  0.864268\n",
       "1   1.217044  1.103197  0.857435\n",
       "2   1.206429  1.098375  0.851549\n",
       "3   1.197270  1.094198  0.846326\n",
       "4   1.189172  1.090491  0.841638\n",
       "..       ...       ...       ...\n",
       "64  1.078494  1.038506  0.758642\n",
       "65  1.078260  1.038393  0.758239\n",
       "66  1.078050  1.038292  0.757860\n",
       "67  1.077845  1.038193  0.757477\n",
       "68  0.000000  0.000000  0.000000\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base SVD RMSE on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1106551598457222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = svd.predict(input_test)\n",
    "rmse = sqrt(mean_squared_error(input_test['rating'], pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import surprise\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = train[['reviewerID', 'asin', 'overall']].rename(columns={\"reviewerID\": \"userID\", \"asin\": \"itemID\", \"overall\": \"rating\"})\n",
    "input_valid = valid[['reviewerID', 'asin', 'overall']].rename(columns={\"reviewerID\": \"userID\", \"asin\": \"itemID\", \"overall\": \"rating\"})\n",
    "input_test = test[['reviewerID', 'asin', 'overall']].rename(columns={\"reviewerID\": \"userID\", \"asin\": \"itemID\", \"overall\": \"rating\"})\n",
    "train_set = surprise.Dataset.load_from_df(input_train, reader=surprise.Reader('ml-100k')).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 50\n",
      "Processing epoch 51\n",
      "Processing epoch 52\n",
      "Processing epoch 53\n",
      "Processing epoch 54\n",
      "Processing epoch 55\n",
      "Processing epoch 56\n",
      "Processing epoch 57\n",
      "Processing epoch 58\n",
      "Processing epoch 59\n",
      "Processing epoch 60\n",
      "Processing epoch 61\n",
      "Processing epoch 62\n",
      "Processing epoch 63\n",
      "Processing epoch 64\n",
      "Processing epoch 65\n",
      "Processing epoch 66\n",
      "Processing epoch 67\n",
      "Processing epoch 68\n",
      "Processing epoch 69\n",
      "Processing epoch 70\n",
      "Processing epoch 71\n",
      "Processing epoch 72\n",
      "Processing epoch 73\n",
      "Processing epoch 74\n",
      "Processing epoch 75\n",
      "Processing epoch 76\n",
      "Processing epoch 77\n",
      "Processing epoch 78\n",
      "Processing epoch 79\n",
      "Processing epoch 80\n",
      "Processing epoch 81\n",
      "Processing epoch 82\n",
      "Processing epoch 83\n",
      "Processing epoch 84\n",
      "Processing epoch 85\n",
      "Processing epoch 86\n",
      "Processing epoch 87\n",
      "Processing epoch 88\n",
      "Processing epoch 89\n",
      "Processing epoch 90\n",
      "Processing epoch 91\n",
      "Processing epoch 92\n",
      "Processing epoch 93\n",
      "Processing epoch 94\n",
      "Processing epoch 95\n",
      "Processing epoch 96\n",
      "Processing epoch 97\n",
      "Processing epoch 98\n",
      "Processing epoch 99\n",
      "Took 117.19449569999998 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "surprise_svd = surprise.SVD(random_state=0, n_factors=n_factors, n_epochs=n_epochs, verbose = True)\n",
    "with Timer() as train_time:\n",
    "    surprise_svd.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0003492LQH8LJXPWDMZ</td>\n",
       "      <td>B00ZJRHSRW</td>\n",
       "      <td>3.691310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0003492LQH8LJXPWDMZ</td>\n",
       "      <td>B01FY9XN00</td>\n",
       "      <td>3.314026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003492LQH8LJXPWDMZ</td>\n",
       "      <td>B00U0I3N4M</td>\n",
       "      <td>3.691310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0003492LQH8LJXPWDMZ</td>\n",
       "      <td>B00DJACZ56</td>\n",
       "      <td>3.691310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0020356UF96ZV361ST</td>\n",
       "      <td>1983730742</td>\n",
       "      <td>4.151955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userID      itemID  prediction\n",
       "0  A0003492LQH8LJXPWDMZ  B00ZJRHSRW    3.691310\n",
       "1  A0003492LQH8LJXPWDMZ  B01FY9XN00    3.314026\n",
       "2  A0003492LQH8LJXPWDMZ  B00U0I3N4M    3.691310\n",
       "3  A0003492LQH8LJXPWDMZ  B00DJACZ56    3.691310\n",
       "4   A0020356UF96ZV361ST  1983730742    4.151955"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(surprise_svd, input_test, usercol='userID', itemcol='itemID')\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "5238\n"
     ]
    }
   ],
   "source": [
    "user_num = pd.unique(input_test['userID'])\n",
    "np.random.seed(25)\n",
    "users_5k = np.random.choice(user_num, 1000, replace=False)\n",
    "print(len(users_5k))\n",
    "test_5k = input_test[input_test['userID'].isin(users_5k)]\n",
    "print(len(pd.unique(test_5k['userID'])))\n",
    "print(len(pd.unique(test_5k['itemID'])))\n",
    "# test_5k.to_csv(\"../../Data/test_5k.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 36.462647399999696 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    all_predictions = compute_ranking_predictions(surprise_svd, test_5k, usercol='userID', itemcol='itemID', remove_seen=False)\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A100BBKBDGGRHV</td>\n",
       "      <td>B004EPYZP8</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A100BBKBDGGRHV</td>\n",
       "      <td>B00D91GRA4</td>\n",
       "      <td>4.873129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A100BBKBDGGRHV</td>\n",
       "      <td>B00QUFHWMS</td>\n",
       "      <td>3.750741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A100BBKBDGGRHV</td>\n",
       "      <td>B01D64VSYI</td>\n",
       "      <td>4.995603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A100BBKBDGGRHV</td>\n",
       "      <td>6302554713</td>\n",
       "      <td>4.947628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userID      itemID  prediction\n",
       "0  A100BBKBDGGRHV  B004EPYZP8    5.000000\n",
       "1  A100BBKBDGGRHV  B00D91GRA4    4.873129\n",
       "2  A100BBKBDGGRHV  B00QUFHWMS    3.750741\n",
       "3  A100BBKBDGGRHV  B01D64VSYI    4.995603\n",
       "4  A100BBKBDGGRHV  6302554713    4.947628"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t1.143431\n",
      "MAE:\t\t0.795445\n",
      "rsquared:\t0.063724\n",
      "exp var:\t0.064050\n",
      "----\n",
      "MAP:\t0.000862\n",
      "NDCG@10:\t0.001894\n",
      "Precision@10:\t0.001300\n",
      "Recall@10:\t0.002339\n"
     ]
    }
   ],
   "source": [
    "eval_rmse = rmse(input_test, predictions)\n",
    "eval_mae = mae(input_test, predictions)\n",
    "eval_rsquared = rsquared(input_test, predictions)\n",
    "eval_exp_var = exp_var(input_test, predictions)\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')\n",
    "print('----')\n",
    "\n",
    "k = 10\n",
    "eval_map = map_at_k(test_5k, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_at_k(test_5k, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_precision = precision_at_k(test_5k, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_recall = recall_at_k(test_5k, all_predictions, col_prediction='prediction', k=k)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG@%d:\\t%f\" % (k, eval_ndcg),\n",
    "      \"Precision@%d:\\t%f\" % (k, eval_precision),\n",
    "      \"Recall@%d:\\t%f\" % (k, eval_recall), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcf1d46d271c46101d6967829d4a5f475342a2ce08e4944f989fbcdc9bb23690"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
